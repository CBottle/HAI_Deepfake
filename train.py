"""
HAI Deepfake Detection - Training Script

í•™ìŠµ ì½”ë“œ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
"""

import argparse
import os
import shutil
from pathlib import Path

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from transformers import ViTImageProcessor
from tqdm import tqdm
from sklearn.metrics import roc_auc_score
from torchvision import transforms
import albumentations as A
from albumentations.pytorch import ToTensorV2
import numpy as np

from src.models import DeepfakeDetector
from src.dataset import DeepfakeDataset
from src.utils import (
    set_seed,
    load_config,
    save_checkpoint,
    load_checkpoint,
    get_device,
    AverageMeter
)


def parse_args():
    """ëª…ë ¹í–‰ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(description='Train Deepfake Detection Model')
    parser.add_argument('--config', type=str, default='config/config.yaml',
                        help='Path to config file')
    parser.add_argument('--resume', type=str, default=None,
                        help='Path to checkpoint to resume from')
    parser.add_argument('--debug', action='store_true',
                        help='Debug mode (small dataset)')
    return parser.parse_args()

def train_epoch(model, dataloader, criterion, optimizer, device, scaler=None):
    """
    í•œ ì—í¬í¬ í•™ìŠµ

    Args:
        model: í•™ìŠµí•  ëª¨ë¸
        dataloader: ë°ì´í„° ë¡œë”
        criterion: ì†ì‹¤ í•¨ìˆ˜
        optimizer: ì˜µí‹°ë§ˆì´ì €
        device: ë””ë°”ì´ìŠ¤
        scaler: GradScaler (Mixed Precision)

    Returns:
        í‰ê·  ì†ì‹¤
    """
    model.train()
    loss_meter = AverageMeter()

    pbar = tqdm(dataloader, desc='Training')
    for batch in pbar:
        pixel_values = batch['pixel_values'].to(device)
        labels = batch['labels'].to(device)

        optimizer.zero_grad()

        # Mixed Precision Training
        if scaler is not None:
            with torch.cuda.amp.autocast():
                logits = model(pixel_values)
                loss = criterion(logits, labels)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else:
            logits = model(pixel_values)
            loss = criterion(logits, labels)
            loss.backward()
            optimizer.step()

        loss_meter.update(loss.item(), pixel_values.size(0))
        pbar.set_postfix({'loss': f'{loss_meter.avg:.4f}'})

    return loss_meter.avg


def validate(model, dataloader, criterion, device):
    """
    ê²€ì¦

    Args:
        model: ëª¨ë¸
        dataloader: ë°ì´í„° ë¡œë”
        criterion: ì†ì‹¤ í•¨ìˆ˜
        device: ë””ë°”ì´ìŠ¤

    Returns:
        í‰ê·  ì†ì‹¤, ROC-AUC
    """
    model.eval()
    loss_meter = AverageMeter()

    all_probs = []
    all_labels = []

    with torch.no_grad():
        pbar = tqdm(dataloader, desc='Validation')
        for batch in pbar:
            pixel_values = batch['pixel_values'].to(device)
            labels = batch['labels'].to(device)

            logits = model(pixel_values)
            loss = criterion(logits, labels)

            probs = torch.softmax(logits, dim=1)[:, 1]  # Fake í™•ë¥ 

            all_probs.extend(probs.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            loss_meter.update(loss.item(), pixel_values.size(0))
            pbar.set_postfix({'loss': f'{loss_meter.avg:.4f}'})

    # ROC-AUC ê³„ì‚°
    auc = roc_auc_score(all_labels, all_probs)

    return loss_meter.avg, auc


# í•™ìŠµ ë°ì´í„°ë¥¼ ìœ„í•œ 'ìˆœí•œ ë§›' ì¦ê°• ì„¤ì • (Soft Augmentation)
# í™”ì§ˆì„ ì†ìƒì‹œí‚¤ì§€ ì•Šê³  í˜•íƒœì˜ ë‹¤ì–‘ì„±ë§Œ í™•ë³´í•©ë‹ˆë‹¤.
soft_transform = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.3),
    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.2),
])


def main():
    """ìˆœí•œ ë§› ì¦ê°• ë²„ì „ - ê³ ë“ì  Fine-tuningìš©"""
    args = parse_args()
    config = load_config(args.config)
    set_seed(config['experiment']['seed'])

    # 1. ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = get_device() 
    print(f"ğŸš€ í•™ìŠµ ì‹œì‘! ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

    # ëª¨ë¸ ì´ˆê¸°í™”
    # ProcessorëŠ” Hugging Faceì˜ ViTìš©ì„ ë¹Œë ¤ ì”€ (EfficientNetë„ 224x224 Normalizeë¼ í˜¸í™˜ë¨)
    processor = ViTImageProcessor.from_pretrained("google/vit-base-patch16-224")
    model = DeepfakeDetector(
        model_name=config['model']['name'],
        num_classes=config['model']['num_classes'],
        pretrained=config['model']['pretrained']
    ).to(device)

    # 2. ë°ì´í„° ìƒ˜í”Œë§ (Real:Fake = 1:1 ë°¸ëŸ°ì‹±)
    import pandas as pd
    from sklearn.model_selection import train_test_split

    train_csv_path = config['data']['train_csv']
    if os.path.exists(train_csv_path):
        full_df = pd.read_csv(train_csv_path)
        
        # í´ë˜ìŠ¤ ë¶„ë¦¬
        df_real = full_df[full_df['label'] == 0]
        df_fake = full_df[full_df['label'] == 1]
        
        target_per_class = 15000
        
        # ê° í´ë˜ìŠ¤ì—ì„œ 1.5ë§Œ ì¥ì”© ìƒ˜í”Œë§
        s_real = df_real.sample(n=min(target_per_class, len(df_real)), random_state=42)
        s_fake = df_fake.sample(n=min(target_per_class, len(df_fake)), random_state=42)
        
        # ë°ì´í„° ë³‘í•©
        balanced_df = pd.concat([s_real, s_fake]).sample(frac=1, random_state=42).reset_index(drop=True)
        
        # Train / Val ë¶„ë¦¬ (9:1)
        train_df, val_df = train_test_split(balanced_df, test_size=0.1, random_state=42, stratify=balanced_df['label'])
        
        print(f"ğŸ“Š [ìˆœí•œë§›] ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: ì´ {len(balanced_df)}ì¥")
        print(f"   - í•™ìŠµ(Train): {len(train_df)}ì¥")
        print(f"   - ê²€ì¦(Val):   {len(val_df)}ì¥")
        
        # ì„ì‹œ íŒŒì¼ ì €ì¥
        train_df.to_csv("temp_train.csv", index=False)
        val_df.to_csv("temp_val.csv", index=False)
    else:
        raise FileNotFoundError(f"âš ï¸ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {train_csv_path}")

    # 3. ë°ì´í„°ì…‹ ë° ë¡œë”
    train_dataset = DeepfakeDataset(
        csv_path="temp_train.csv",
        img_dir=config['data']['img_dir'],
        processor=processor,
        num_frames=config['data']['num_frames'],
        transform=soft_transform # ìˆœí•œë§› ì ìš©
    )
    
    val_dataset = DeepfakeDataset(
        csv_path="temp_val.csv",
        img_dir=config['data']['img_dir'],
        processor=processor,
        num_frames=config['data']['num_frames'],
        transform=None 
    )

    train_loader = DataLoader(
        train_dataset,
        batch_size=config['training']['batch_size'],
        shuffle=True,
        num_workers=config['training']['num_workers'],
        pin_memory=True if device == 'cuda' else False
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['training']['batch_size'],
        shuffle=False,
        num_workers=config['training']['num_workers'],
        pin_memory=True if device == 'cuda' else False
    )

    # 4. ì˜µí‹°ë§ˆì´ì € (ì´ˆë°˜ ìˆ˜ë ´ ì†ë„ë¥¼ ìœ„í•´ LR ìƒí–¥: 1e-5 -> 1e-4)
    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)
    
    # ìŠ¤ì¼€ì¤„ëŸ¬: ì›œì—…(Warmup) í›„ ì½”ì‚¬ì¸ ì–´ë‹ë§
    # ì´ˆë°˜ 1ì—í¬í¬ ë™ì•ˆì€ í•™ìŠµë¥ ì„ ì„œì„œíˆ ì˜¬ë¦¬ê³ , ê·¸ ë’¤ë¡œëŠ” ì„œì„œíˆ ë‚®ì¶¤ (ì•ˆì •ì  í•™ìŠµ)
    from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR, SequentialLR
    
    warmup_scheduler = LinearLR(optimizer, start_factor=0.1, end_factor=1.0, total_iters=len(train_loader))
    cosine_scheduler = CosineAnnealingLR(optimizer, T_max=config['training']['epochs'] * len(train_loader))
    
    # 1ì—í¬í¬ ì›œì—… í›„ ë‚˜ë¨¸ì§€ ê¸°ê°„ ì½”ì‚¬ì¸ ì–´ë‹ë§
    scheduler = SequentialLR(optimizer, schedulers=[warmup_scheduler, cosine_scheduler], milestones=[len(train_loader)])
    criterion = torch.nn.CrossEntropyLoss()

    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (Resume)
    start_epoch = 0
    best_auc = 0.0
    
    if args.resume:
        if os.path.isfile(args.resume):
            print(f"ğŸ”„ Resuming from checkpoint: {args.resume}")
            checkpoint = load_checkpoint(args.resume, model, optimizer, device)
            start_epoch = checkpoint['epoch'] + 1
            if 'val_auc' in checkpoint:
                best_auc = checkpoint['val_auc']
            print(f"   -> Resuming from Epoch {start_epoch+1}")
        else:
            print(f"âš ï¸ Checkpoint not found: {args.resume}")

    # í•™ìŠµ ë£¨í”„
    print(f"\n=== Start Fine-tuning (Total Epochs: {config['training']['epochs']}) ===")
    ckpt_dir = config['training']['experiment']['output_dir']
    
    for epoch in range(start_epoch, config['training']['epochs']):
        # 1. í•™ìŠµ
        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)
        
        # 2. ê²€ì¦
        val_loss, val_auc = validate(model, val_loader, criterion, device)
        
        print(f"Epoch {epoch+1}/{config['training']['epochs']} | "
              f"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val AUC: {val_auc:.4f}")
        
        # 3. ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        is_best = val_auc > best_auc
        if is_best:
            best_auc = val_auc
            print(f"ğŸ† Best AUC Updated: {best_auc:.4f}")
        
        save_checkpoint(
            model, 
            optimizer, 
            epoch, 
            val_auc, 
            checkpoint_dir=ckpt_dir, 
            is_best=is_best
        )

        scheduler.step()

if __name__ == '__main__':
    main()
