{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAI Deepfake Detection - Colab Training Pipeline\n",
    "\n",
    "**4가지 핵심 임무:**\n",
    "1. **코드 동기화 (Git Sync)** - 로컬에서 push한 코드를 Colab에 자동 동기화\n",
    "2. **자동 환경 세팅 (Environment Setup)** - 필요한 라이브러리 자동 설치\n",
    "3. **데이터 고속도로 (Data Loading)** - Kaggle API로 대용량 데이터 직접 다운로드\n",
    "4. **금고 보관 (Model Persistence)** - Google Drive에 학습된 모델 자동 백업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. GPU 확인\n",
    "Colab에서 GPU가 활성화되어 있는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU 사용 가능: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA 버전: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"GPU를 사용할 수 없습니다. 런타임 > 런타임 유형 변\" \\\n",
    "    \"경 > GPU 선택\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 금고 보관 (Model Persistence) - Google Drive 마운트\n",
    "학습된 모델을 안전하게 보관하기 위해 Google Drive를 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Google Drive 마운트\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 백업 디렉토리 생성\n",
    "import os\n",
    "DRIVE_BACKUP_DIR = '/content/drive/MyDrive/HAI_Deepfake'\n",
    "os.makedirs(f\"{DRIVE_BACKUP_DIR}/models\", exist_ok=True)\n",
    "os.makedirs(f\"{DRIVE_BACKUP_DIR}/checkpoints\", exist_ok=True)\n",
    "print(f\"백업 디렉토리 준비 완료: {DRIVE_BACKUP_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. 코드 동기화 (Git Sync)\n",
    "GitHub에서 최신 코드를 가져옵니다. 로컬에서 `git push` 후 이 셀만 실행하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# GitHub 설정\n",
    "REPO_URL = \"https://github.com/CBottle/HAI_Deepfake.git\"\n",
    "PROJECT_DIR = \"/content/HAI_Deepfake\"\n",
    "BRANCH = \"HK\"  # <--- 동기화할 브랜치 이름 (HK 또는 main)\n",
    "\n",
    "if os.path.exists(PROJECT_DIR):\n",
    "    print(f\"기존 프로젝트 발견! {BRANCH} 브랜치 최신 코드로 업데이트 중...\")\n",
    "    %cd {PROJECT_DIR}\n",
    "    !git fetch --all\n",
    "    # 브랜치 전환 및 리셋\n",
    "    !git checkout {BRANCH} || git checkout -b {BRANCH} origin/{BRANCH}\n",
    "    !git reset --hard origin/{BRANCH}\n",
    "    print(f\"\\n{BRANCH} 브랜치 코드 동기화 완료!\")\n",
    "else:\n",
    "    print(f\"프로젝트 클론 중... (브랜치: {BRANCH})\")\n",
    "    !git clone -b {BRANCH} {REPO_URL} {PROJECT_DIR}\n",
    "    %cd {PROJECT_DIR}\n",
    "    print(f\"\\n클론 및 {BRANCH} 브랜치 전환 완료!\")\n",
    "\n",
    "# 현재 커밋 및 브랜치 확인\n",
    "print(\"\\n현재 정보:\")\n",
    "!git branch --show-current\n",
    "!git log -1 --oneline\n",
    "print(f\"\\n작업 디렉토리: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. 자동 환경 세팅 (Environment Setup)\n",
    "`requirements.txt`를 읽어 필요한 라이브러리를 자동으로 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# requirements.txt 경로 확인\n",
    "req_paths = ['requirements.txt', 'env/requirements.txt']\n",
    "req_file = None\n",
    "\n",
    "for path in req_paths:\n",
    "    if os.path.exists(path):\n",
    "        req_file = path\n",
    "        break\n",
    "\n",
    "if req_file:\n",
    "    print(f\"패키지 설치 중: {req_file}\")\n",
    "    print(\"=\"*50)\n",
    "    !pip install -q -r {req_file}\n",
    "    print(\"=\"*50)\n",
    "    print(\"환경 설정 완료!\")\n",
    "else:\n",
    "    print(\"requirements.txt를 찾을 수 없습니다.\")\n",
    "    print(\"기본 패키지를 설치합니다...\")\n",
    "    !pip install -q torch torchvision transformers pillow opencv-python scikit-learn tqdm pyyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. 데이터 고속도로 (Data Loading) - Kaggle API\n",
    "Kaggle 서버에서 Colab 서버로 데이터를 직접 다운로드합니다. (내 컴퓨터를 거치지 않아 빠름!)\n",
    "\n",
    "**사전 준비:**\n",
    "1. Kaggle 계정에서 `kaggle.json` 다운로드 (Account > API > Create New Token)\n",
    "2. Google Drive의 `/MyDrive/Kaggle/kaggle.json`에 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "\n",
    "# Kaggle API 설정\n",
    "KAGGLE_CONFIG_DIR = '/root/.kaggle'\n",
    "DRIVE_KAGGLE_KEY = '/content/drive/MyDrive/Kaggle/kaggle.json'\n",
    "\n",
    "os.makedirs(KAGGLE_CONFIG_DIR, exist_ok=True)\n",
    "\n",
    "if os.path.exists(DRIVE_KAGGLE_KEY):\n",
    "    !cp {DRIVE_KAGGLE_KEY} {KAGGLE_CONFIG_DIR}/\n",
    "    !chmod 600 {KAGGLE_CONFIG_DIR}/kaggle.json\n",
    "    print(\"Kaggle API 키 설정 완료!\")\n",
    "    KAGGLE_READY = True\n",
    "else:\n",
    "    print(\"kaggle.json을 찾을 수 없습니다.\")\n",
    "    print(f\"Google Drive에 파일을 업로드해주세요: {DRIVE_KAGGLE_KEY}\")\n",
    "    KAGGLE_READY = False\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ============================================\n",
    "# Kaggle 데이터셋 다운로드\n",
    "# 아래 DATASET_NAME을 본인의 데이터셋으로 변경하세요!\n",
    "# ============================================\n",
    "\n",
    "# 예시 데이터셋 (변경 필요)\n",
    "DATASET_NAME = \"manjilkarki/deepfake-and-real-images\"  # Kaggle 데이터셋 경로\n",
    "DATA_DIR = \"./train_data\"\n",
    "\n",
    "if KAGGLE_READY:\n",
    "    # 기존 데이터가 있는지 확인\n",
    "    if os.path.exists(DATA_DIR) and len(os.listdir(DATA_DIR)) > 0:\n",
    "        print(f\"데이터가 이미 존재합니다: {DATA_DIR}\")\n",
    "        !ls -la {DATA_DIR}\n",
    "    else:\n",
    "        print(f\"데이터셋 다운로드 중: {DATASET_NAME}\")\n",
    "        !kaggle datasets download -d {DATASET_NAME} -p {DATA_DIR} --unzip\n",
    "        print(\"다운로드 완료!\")\n",
    "else:\n",
    "    print(\"Kaggle API가 설정되지 않았습니다.\")\n",
    "    print(\"더미 데이터를 생성합니다...\")\n",
    "    !python create_dummy_data.py\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다운로드X 구글 드라이브에서 zip폴더 가지고 오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/HAI_Deepfake/extracted_frames.zip /content/extracted_data.zip\n",
    "!unzip -q /content/extracted_data.zip -d /content/train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. 학습 실행\n",
    "GPU를 사용하여 모델을 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 시작 전 데이터 확인\n",
    "import os\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"학습 데이터 구조:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if os.path.exists('train_data'):\n",
    "    !ls -la train_data/\n",
    "    if os.path.exists('train_data/Train'):\n",
    "        real_count1 = len(os.listdir('train_data/Train/Real'))\n",
    "        print(f\"\\ntrain-Real 이미지: {real_count1}개\")\n",
    "        fake_count1 = len(os.listdir('train_data/Train/Fake'))\n",
    "        print(f\"\\ntrain-Fake 이미지: {fake_count1}개\")\n",
    "    if os.path.exists('train_data/Validation'):\n",
    "        real_count2 = len(os.listdir('train_data/Validation/Real'))\n",
    "        print(f\"\\nval-Real 이미지: {real_count2}개\")\n",
    "        fake_count2 = len(os.listdir('train_data/Validation/Fake'))\n",
    "        print(f\"\\nval-Fake 이미지: {fake_count2}개\")\n",
    "else:\n",
    "    print(\"train_data 폴더가 없습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 실행\n",
    "!python train.py --config config/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. (선택) 추론 테스트\n",
    "학습된 모델로 테스트 데이터 추론을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/HAI_Deepfake/open.zip /content/test_data.zip\n",
    "!unzip -q /content/test_data.zip -d /content/test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 실행 (체크포인트 경로 확인 필요)\n",
    "!python inference.py \\\n",
    "    --model /content/drive/MyDrive/HAI_Deepfake/checkpoints/best_model.pt \\\n",
    "    --test_dir /content/test_data/test_data \\\n",
    "    --output submissions/submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 빠른 실행 가이드\n",
    "\n",
    "1. **런타임 > 런타임 유형 변경 > GPU 선택**\n",
    "2. **런타임 > 모두 실행** 또는 `Ctrl+F9`\n",
    "3. Google Drive 마운트 승인\n",
    "4. 학습 완료 후 모델은 자동으로 Drive에 백업됨\n",
    "\n",
    "### 코드 업데이트 시\n",
    "로컬에서 `git push` 후, **섹션 2 (코드 동기화)** 셀만 다시 실행하면 됩니다!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
