{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ HAI Deepfake - ë°ì´í„° ì¤€ë¹„ ë…¸íŠ¸ë¶ (Colab)\n",
    "\n",
    "**ì´ ë…¸íŠ¸ë¶ì˜ ëª©ì :**\n",
    "1. âœ… Kaggle ë°ì´í„°ì…‹ì„ Google Driveë¡œ ë‹¤ìš´ë¡œë“œ\n",
    "2. âœ… ë°ì´í„° í´ë” êµ¬ì¡° ì •ë¦¬ (real/fake)\n",
    "3. âœ… ì†Œê·œëª¨ ë°ì´í„°ì…‹ ìƒì„± (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)\n",
    "4. âœ… ë°ì´í„° ê²€ì¦\n",
    "\n",
    "**ì‚¬ìš© ë°ì´í„°ì…‹:** `manjilkarki/deepfake-and-real-images`\n",
    "\n",
    "**ì‘ì—… ìˆœì„œ:**\n",
    "- ë‹¨ê³„ë³„ë¡œ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”\n",
    "- ì²« ì‹¤í–‰ ì‹œ ì „ì²´ ì‹¤í–‰ (ì•½ 30ë¶„)\n",
    "- ì´í›„ì—ëŠ” í•„ìš”í•œ ì„¹ì…˜ë§Œ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Œ Step 0: í™˜ê²½ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ” í™˜ê²½ ì •ë³´\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   CUDA: {torch.version.cuda}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸  GPU ì—†ìŒ - 'ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > GPU' ì„ íƒí•˜ì„¸ìš”!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Œ Step 1: Google Drive ë§ˆìš´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Google Drive ë§ˆìš´íŠ¸\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •\n",
    "DRIVE_ROOT = Path(\"/content/drive/MyDrive/HAI_Deepfake\")\n",
    "DRIVE_ROOT.mkdir(exist_ok=True)\n",
    "\n",
    "# í•˜ìœ„ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "(DRIVE_ROOT / \"datasets\").mkdir(exist_ok=True)\n",
    "(DRIVE_ROOT / \"train_data\").mkdir(exist_ok=True)\n",
    "(DRIVE_ROOT / \"train_data_small\").mkdir(exist_ok=True)\n",
    "(DRIVE_ROOT / \"models\").mkdir(exist_ok=True)\n",
    "(DRIVE_ROOT / \"checkpoints\").mkdir(exist_ok=True)\n",
    "\n",
    "print(\"âœ… Google Drive ë§ˆìš´íŠ¸ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {DRIVE_ROOT}\")\n",
    "print(f\"\\nğŸ“‚ ë””ë ‰í† ë¦¬ êµ¬ì¡°:\")\n",
    "print(f\"  {DRIVE_ROOT}/\")\n",
    "print(f\"  â”œâ”€â”€ datasets/         # Kaggle ì›ë³¸ ë°ì´í„°\")\n",
    "print(f\"  â”œâ”€â”€ train_data/       # ì „ì²˜ë¦¬ëœ í•™ìŠµ ë°ì´í„°\")\n",
    "print(f\"  â”œâ”€â”€ train_data_small/ # ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸ ë°ì´í„°\")\n",
    "print(f\"  â”œâ”€â”€ models/           # ìµœì¢… ëª¨ë¸\")\n",
    "print(f\"  â””â”€â”€ checkpoints/      # í•™ìŠµ ì²´í¬í¬ì¸íŠ¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Œ Step 2: í”„ë¡œì íŠ¸ ì½”ë“œ ë™ê¸°í™” (Git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_URL = \"https://github.com/CBottle/HAI_Deepfake.git\"\n",
    "PROJECT_DIR = \"/content/HAI_Deepfake\"\n",
    "\n",
    "if os.path.exists(PROJECT_DIR):\n",
    "    print(\"ğŸ”„ ê¸°ì¡´ ì½”ë“œ ì—…ë°ì´íŠ¸ ì¤‘...\")\n",
    "    %cd {PROJECT_DIR}\n",
    "    !git fetch --all\n",
    "    !git reset --hard origin/main\n",
    "    print(\"âœ… ì½”ë“œ ì—…ë°ì´íŠ¸ ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(\"ğŸ“¥ í”„ë¡œì íŠ¸ í´ë¡  ì¤‘...\")\n",
    "    !git clone {REPO_URL} {PROJECT_DIR}\n",
    "    %cd {PROJECT_DIR}\n",
    "    print(\"âœ… í´ë¡  ì™„ë£Œ!\")\n",
    "\n",
    "# ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "print(f\"\\nğŸ“ í˜„ì¬ ìœ„ì¹˜: {os.getcwd()}\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Œ Step 3: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘...\\n\")\n",
    "\n",
    "# requirements.txtê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì§ì ‘ ì„¤ì¹˜\n",
    "if os.path.exists(\"env/requirements.txt\"):\n",
    "    !pip install -q -r env/requirements.txt\n",
    "else:\n",
    "    !pip install -q kaggle opencv-python tqdm pillow pandas scikit-learn\n",
    "\n",
    "print(\"\\nâœ… ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Œ Step 4: Kaggle API ì„¤ì •\n",
    "\n",
    "**âš ï¸ ì¤‘ìš”: ì²˜ìŒ ì‹¤í–‰ ì‹œ kaggle.json ì—…ë¡œë“œ í•„ìš”**\n",
    "\n",
    "### Kaggle API í† í° ë°›ëŠ” ë°©ë²•:\n",
    "1. https://www.kaggle.com/settings ì ‘ì†\n",
    "2. \"Create New API Token\" í´ë¦­\n",
    "3. ë‹¤ìš´ë¡œë“œëœ `kaggle.json` íŒŒì¼ì„ Google Driveì— ì—…ë¡œë“œ:\n",
    "   - ìœ„ì¹˜: `/MyDrive/HAI_Deepfake/kaggle.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# kaggle.json ê²½ë¡œ\n",
    "kaggle_json_drive = DRIVE_ROOT / \"kaggle.json\"\n",
    "kaggle_json_local = Path.home() / \".kaggle\" / \"kaggle.json\"\n",
    "\n",
    "if kaggle_json_drive.exists():\n",
    "    print(\"âœ… kaggle.json íŒŒì¼ ë°œê²¬!\")\n",
    "    \n",
    "    # ~/.kaggle ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    kaggle_json_local.parent.mkdir(exist_ok=True)\n",
    "    \n",
    "    # ë³µì‚¬\n",
    "    shutil.copy(kaggle_json_drive, kaggle_json_local)\n",
    "    \n",
    "    # ê¶Œí•œ ì„¤ì •\n",
    "    os.chmod(kaggle_json_local, 0o600)\n",
    "    \n",
    "    print(\"âœ… Kaggle API ì„¤ì • ì™„ë£Œ!\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸\n",
    "    !kaggle datasets list --max-size 1000 | head -5\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ kaggle.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    print(f\"\\nğŸ“ ë‹¤ìŒ ê²½ë¡œì— ì—…ë¡œë“œí•˜ì„¸ìš”:\")\n",
    "    print(f\"   {kaggle_json_drive}\")\n",
    "    print(f\"\\nğŸ’¡ Kaggle API í† í° ë°›ëŠ” ë°©ë²•:\")\n",
    "    print(f\"   1. https://www.kaggle.com/settings\")\n",
    "    print(f\"   2. 'Create New API Token' í´ë¦­\")\n",
    "    print(f\"   3. ë‹¤ìš´ë¡œë“œëœ kaggle.jsonì„ ìœ„ ê²½ë¡œì— ì—…ë¡œë“œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Œ Step 5: ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
    "\n",
    "### ì‚¬ìš© ë°ì´í„°ì…‹:\n",
    "- **Deepfake and Real Images** - ì´ë¯¸ì§€ í˜•íƒœ (í”„ë ˆì„ ì¶”ì¶œ ë¶ˆí•„ìš”!)\n",
    "- Kaggle: `manjilkarki/deepfake-and-real-images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ê²½ë¡œ ì„¤ì •\n",
    "DATASET_NAME = \"manjilkarki/deepfake-and-real-images\"\n",
    "DATASET_OUTPUT = DRIVE_ROOT / \"datasets\" / \"deepfake-real-images\"\n",
    "DATASET_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“¦ ë°ì´í„°ì…‹: {DATASET_NAME}\")\n",
    "print(f\"ğŸ“ ì €ì¥ ê²½ë¡œ: {DATASET_OUTPUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
    "print(\"ğŸ“¥ Deepfake and Real Images ë‹¤ìš´ë¡œë“œ ì‹œì‘...\")\n",
    "print(\"â±ï¸  ì˜ˆìƒ ì‹œê°„: 10~30ë¶„ (ë„¤íŠ¸ì›Œí¬ ì†ë„ì— ë”°ë¼ ë‹¤ë¦„)\\n\")\n",
    "\n",
    "!kaggle datasets download -d {DATASET_NAME} -p {DATASET_OUTPUT} --unzip\n",
    "\n",
    "print(\"\\nâœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“ ì €ì¥ ìœ„ì¹˜: {DATASET_OUTPUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ìš´ë¡œë“œëœ í´ë” êµ¬ì¡° í™•ì¸\n",
    "print(\"ğŸ“‚ ë‹¤ìš´ë¡œë“œëœ í´ë” êµ¬ì¡°:\")\n",
    "!find {DATASET_OUTPUT} -type d | head -20\n",
    "\n",
    "print(\"\\nğŸ“Š ì´ë¯¸ì§€ ê°œìˆ˜:\")\n",
    "!find {DATASET_OUTPUT} -name \"*.jpg\" -o -name \"*.png\" -o -name \"*.jpeg\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ ìš©ëŸ‰ í™•ì¸\n",
    "print(\"ğŸ’¾ ë°ì´í„°ì…‹ ìš©ëŸ‰:\")\n",
    "!du -sh {DATASET_OUTPUT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Œ Step 6: ë°ì´í„° í´ë” êµ¬ì¡° ì •ë¦¬\n",
    "\n",
    "ë‹¤ìš´ë¡œë“œëœ ë°ì´í„°ë¥¼ `real/`, `fake/` í´ë” êµ¬ì¡°ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**âš ï¸ ì´ ë‹¨ê³„ëŠ” ë°ì´í„°ì…‹ êµ¬ì¡°ì— ë”°ë¼ ìˆ˜ë™ ì¡°ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ë°ì´í„° í´ë” ìƒì„±\n",
    "TRAIN_DATA_DIR = DRIVE_ROOT / \"train_data\"\n",
    "(TRAIN_DATA_DIR / \"real\").mkdir(parents=True, exist_ok=True)\n",
    "(TRAIN_DATA_DIR / \"fake\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“ í•™ìŠµ ë°ì´í„° í´ë”: {TRAIN_DATA_DIR}\")\n",
    "print(f\"   â”œâ”€â”€ real/\")\n",
    "print(f\"   â””â”€â”€ fake/\")\n",
    "\n",
    "print(\"\\nğŸ“‚ ë‹¤ìš´ë¡œë“œëœ ë°ì´í„° êµ¬ì¡° í™•ì¸:\")\n",
    "!ls -la {DATASET_OUTPUT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ êµ¬ì¡°ì— ë§ê²Œ ë³µì‚¬/ì´ë™\\n\",\n",
    "    \"# âš ï¸ ì•„ë˜ ê²½ë¡œëŠ” ì‹¤ì œ ë‹¤ìš´ë¡œë“œëœ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”!\\n\",\n",
    "    \"\\n\",\n",
    "    \"import shutil\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ì˜ˆì‹œ: ë°ì´í„°ì…‹ì— 'Real'ê³¼ 'Fake' í´ë”ê°€ ìˆëŠ” ê²½ìš°\\n\",\n",
    "    \"# ì‹¤ì œ êµ¬ì¡°ë¥¼ í™•ì¸ í›„ ì•„ë˜ ê²½ë¡œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ë°©ë²• 1: ì‹¬ë³¼ë¦­ ë§í¬ (ìš©ëŸ‰ ì ˆì•½)\\n\",\n",
    "    \"# !ln -s {DATASET_OUTPUT}/Real/* {TRAIN_DATA_DIR}/real/\\n\",\n",
    "    \"# !ln -s {DATASET_OUTPUT}/Fake/* {TRAIN_DATA_DIR}/fake/\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ë°©ë²• 2: ë³µì‚¬ (ì•ˆì „)\\n\",\n",
    "    \"# !cp -r {DATASET_OUTPUT}/Real/* {TRAIN_DATA_DIR}/real/\\n\",\n",
    "    \"# !cp -r {DATASET_OUTPUT}/Fake/* {TRAIN_DATA_DIR}/fake/\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('âš ï¸  ìœ„ ì£¼ì„ì„ í™•ì¸í•˜ê³ , ë°ì´í„°ì…‹ êµ¬ì¡°ì— ë§ê²Œ ë³µì‚¬ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Œ Step 7: ì†Œê·œëª¨ ë°ì´í„°ì…‹ ìƒì„± (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)\n",
    "\n",
    "ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµí•˜ê¸° ì „ì— ì‘ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì†Œê·œëª¨ ë°ì´í„°ì…‹ ì„¤ì •\n",
    "SMALL_INPUT = str(TRAIN_DATA_DIR)\n",
    "SMALL_OUTPUT = str(DRIVE_ROOT / \"train_data_small\")\n",
    "NUM_SAMPLES = 1000  # í´ë˜ìŠ¤ë‹¹ ìƒ˜í”Œ ìˆ˜ (Real 1000 + Fake 1000 = ì´ 2000)\n",
    "\n",
    "print(f\"ğŸ“‚ ì›ë³¸: {SMALL_INPUT}\")\n",
    "print(f\"ğŸ“ ì¶œë ¥: {SMALL_OUTPUT}\")\n",
    "print(f\"ğŸ“Š ìƒ˜í”Œ: í´ë˜ìŠ¤ë‹¹ {NUM_SAMPLES:,d} ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì†Œê·œëª¨ ë°ì´í„°ì…‹ ìƒì„±\n",
    "!python scripts/create_small_dataset.py \\\n",
    "    --input \"{SMALL_INPUT}\" \\\n",
    "    --output \"{SMALL_OUTPUT}\" \\\n",
    "    --num-samples {NUM_SAMPLES} \\\n",
    "    --seed 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Œ Step 8: ë°ì´í„° ê²€ì¦\n",
    "\n",
    "ìƒì„±ëœ ë°ì´í„°ì…‹ì„ í™•ì¸í•˜ê³  ìƒ˜í”Œ ì´ë¯¸ì§€ë¥¼ ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "def show_samples(data_dir, num_samples=6):\n",
    "    \"\"\"ë°ì´í„°ì…‹ ìƒ˜í”Œ ì‹œê°í™”\"\"\"\n",
    "    data_path = Path(data_dir)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(15, 5))\n",
    "    fig.suptitle(f\"Dataset Samples: {data_dir}\", fontsize=16)\n",
    "    \n",
    "    for idx, label in enumerate([\"real\", \"fake\"]):\n",
    "        label_dir = data_path / label\n",
    "        images = list(label_dir.glob(\"*.jpg\"))\n",
    "        \n",
    "        if len(images) == 0:\n",
    "            print(f\"âš ï¸  {label} ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            continue\n",
    "        \n",
    "        samples = random.sample(images, min(num_samples, len(images)))\n",
    "        \n",
    "        for i, img_path in enumerate(samples):\n",
    "            img = Image.open(img_path)\n",
    "            axes[idx, i].imshow(img)\n",
    "            axes[idx, i].axis('off')\n",
    "            axes[idx, i].set_title(f\"{label.upper()}\", fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ì†Œê·œëª¨ ë°ì´í„°ì…‹ ìƒ˜í”Œ ë³´ê¸°\n",
    "show_samples(SMALL_OUTPUT, num_samples=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ í†µê³„\n",
    "def print_dataset_stats(data_dir):\n",
    "    \"\"\"ë°ì´í„°ì…‹ í†µê³„ ì¶œë ¥\"\"\"\n",
    "    data_path = Path(data_dir)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"ğŸ“Š ë°ì´í„°ì…‹ í†µê³„: {data_dir}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    total = 0\n",
    "    for label in [\"real\", \"fake\"]:\n",
    "        label_dir = data_path / label\n",
    "        if label_dir.exists():\n",
    "            images = list(label_dir.glob(\"*.jpg\"))\n",
    "            images += list(label_dir.glob(\"*.png\"))\n",
    "            count = len(images)\n",
    "            total += count\n",
    "            print(f\"  {label.upper():5s}: {count:8,d} ì´ë¯¸ì§€\")\n",
    "    \n",
    "    print(f\"  {'TOTAL':5s}: {total:8,d} ì´ë¯¸ì§€\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ì…‹\n",
    "print_dataset_stats(SMALL_INPUT)\n",
    "\n",
    "# ì†Œê·œëª¨ ë°ì´í„°ì…‹\n",
    "print_dataset_stats(SMALL_OUTPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## âœ… ì™„ë£Œ!\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„:\n",
    "1. **ì†Œê·œëª¨ë¡œ í•™ìŠµ ì‹œì‘**: `train_colab.ipynb` ì‹¤í–‰\n",
    "2. **ë°ì´í„° ê²½ë¡œ ì„¤ì •**: \n",
    "   - ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸: `/content/drive/MyDrive/HAI_Deepfake/train_data_small`\n",
    "   - ì „ì²´ í•™ìŠµ: `/content/drive/MyDrive/HAI_Deepfake/train_data`\n",
    "\n",
    "### ì €ì¥ëœ ìœ„ì¹˜:\n",
    "- ğŸ“ Google Drive: `/MyDrive/HAI_Deepfake/`\n",
    "- ğŸ“¦ ì›ë³¸ ë°ì´í„°ì…‹: `datasets/deepfake-real-images/`\n",
    "- ğŸ–¼ï¸ ì „ì²´ ì´ë¯¸ì§€: `train_data/` (real/, fake/)\n",
    "- ğŸ§ª í…ŒìŠ¤íŠ¸ ë°ì´í„°: `train_data_small/`\n",
    "\n",
    "### íŒ:\n",
    "- Colab ì„¸ì…˜ì´ ëŠê²¨ë„ Google Drive ë°ì´í„°ëŠ” ì•ˆì „!\n",
    "- ë‹¤ìŒ ë²ˆì—ëŠ” Step 1ë¶€í„° ë°”ë¡œ ì‹œì‘ ê°€ëŠ¥\n",
    "- ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì´ë¼ í”„ë ˆì„ ì¶”ì¶œ ë¶ˆí•„ìš”!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
