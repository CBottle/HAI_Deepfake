{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAI Deepfake - Inference (prithivMLmods Model)\n",
    "\n",
    "**Î™®Îç∏**: `prithivMLmods/Deep-Fake-Detector-v2-Model` (Hugging Face)\n",
    "**Ï†ÑÎûµ**: Top-K Average, RetinaFace Crop Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!pip install -q transformers torch pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ\n",
    "DRIVE_ZIP_PATH = '/content/drive/MyDrive/HAI_Deepfake/processed_test_data.zip'\n",
    "LOCAL_DATA_DIR = '/content/processed_test_data'\n",
    "\n",
    "if not os.path.exists(LOCAL_DATA_DIR):\n",
    "    print(\"üìÇ Îç∞Ïù¥ÌÑ∞ Î≥µÏÇ¨ Î∞è ÏïïÏ∂ï Ìï¥Ï†ú Ï§ë...\")\n",
    "    os.makedirs(LOCAL_DATA_DIR, exist_ok=True)\n",
    "    !cp {DRIVE_ZIP_PATH} /content/data.zip\n",
    "    !unzip -q /content/data.zip -d {LOCAL_DATA_DIR}\n",
    "    print(\"‚úÖ Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ ÏôÑÎ£å!\")\n",
    "else:\n",
    "    print(\"‚úÖ Îç∞Ïù¥ÌÑ∞Í∞Ä Ïù¥ÎØ∏ Ï°¥Ïû¨Ìï©ÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
    "\n",
    "# ÏÑ§Ï†ï\n",
    "MODEL_NAME = \"prithivMLmods/Deep-Fake-Detector-v2-Model\"\n",
    "OUTPUT_CSV = \"submission_prithiv.csv\"\n",
    "\n",
    "class ProcessedDataset(Dataset):\n",
    "    def __init__(self, data_dir, processor=None):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.processor = processor\n",
    "        self.items = sorted([item for item in self.data_dir.glob('*') if not item.name.startswith('.')])\n",
    "        \n",
    "        if len(self.items) == 1 and self.items[0].is_dir():\n",
    "            self.data_dir = self.items[0]\n",
    "            self.items = sorted([item for item in self.data_dir.glob('*') if not item.name.startswith('.')])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item_path = self.items[idx]\n",
    "        pixel_values_list = []\n",
    "        \n",
    "        # Ïù¥ÎØ∏ÏßÄ Î°úÎìú\n",
    "        if item_path.is_dir():\n",
    "            img_paths = sorted(list(item_path.glob('*.jpg')))\n",
    "            frames = [Image.open(p).convert(\"RGB\") for p in img_paths]\n",
    "        else:\n",
    "            frames = [Image.open(item_path).convert(\"RGB\")]\n",
    "\n",
    "        # Processor Ï†ÅÏö© (Hugging Face)\n",
    "        if frames:\n",
    "            inputs = self.processor(images=frames, return_tensors=\"pt\")\n",
    "            pixel_values_list = inputs['pixel_values']\n",
    "        else:\n",
    "            return torch.zeros(1, 3, 224, 224), item_path.name\n",
    "\n",
    "        return pixel_values_list, item_path.name\n",
    "\n",
    "def run_inference():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    print(f\"Loading model: {MODEL_NAME}\")\n",
    "    model = AutoModelForImageClassification.from_pretrained(MODEL_NAME).to(device)\n",
    "    processor = AutoImageProcessor.from_pretrained(MODEL_NAME)\n",
    "    model.eval()\n",
    "    \n",
    "    # ÎùºÎ≤® ÌôïÏù∏\n",
    "    print(f\"Label Map: {model.config.id2label}\")\n",
    "\n",
    "    dataset = ProcessedDataset(LOCAL_DATA_DIR, processor=processor)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "    results = {}\n",
    "    print(f\"üöÄ Starting inference...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for pixel_values, filenames in tqdm(dataloader):\n",
    "            # (1, T, C, H, W) -> (T, C, H, W)\n",
    "            pixel_values = pixel_values.squeeze(0).to(device)\n",
    "            filename = filenames[0]\n",
    "            \n",
    "            outputs = model(pixel_values)\n",
    "            probs = F.softmax(outputs.logits, dim=1)\n",
    "            \n",
    "            # Fake ÌôïÎ•† (Î≥¥ÌÜµ Label 1)\n",
    "            fake_probs = probs[:, 1]\n",
    "            \n",
    "            # Top-K Average (ÏÉÅÏúÑ 5Í∞ú)\n",
    "            k = min(5, len(fake_probs))\n",
    "            top_k_probs, _ = torch.topk(fake_probs, k)\n",
    "            final_prob = float(top_k_probs.mean().cpu().item())\n",
    "            \n",
    "            clean_filename = filename.replace('_frames', '')\n",
    "            results[clean_filename] = final_prob\n",
    "\n",
    "    return results\n",
    "\n",
    "results = run_inference()\n",
    "\n",
    "submission = pd.DataFrame(list(results.items()), columns=['filename', 'prob'])\n",
    "submission.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"‚úÖ Submission saved: {OUTPUT_CSV}\")\n",
    "\n",
    "BACKUP_PATH = '/content/drive/MyDrive/HAI_Deepfake/submission_prithiv.csv'\n",
    "!cp {OUTPUT_CSV} {BACKUP_PATH}\n",
    "print(f\"üíæ Drive Backup: {BACKUP_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
