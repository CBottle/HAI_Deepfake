{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAI Deepfake - Ultimate Inference Pipeline\n",
    "\n",
    "**ëª©í‘œ**: ë¡œì»¬ì—ì„œ ì „ì²˜ë¦¬(RetinaFace Crop)ë¥¼ ì™„ë£Œí•œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬, **ì´ˆê³ ì† & ê³ ì •í™•ë„** ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì¤€ë¹„ë¬¼ (Google Drive):**\n",
    "1. `processed_test_data.zip`: ë¡œì»¬ì—ì„œ ì „ì²˜ë¦¬ê°€ ì™„ë£Œëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹\n",
    "2. `checkpoints/best_model.pt`: (ì„ íƒ) í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜. ì—†ìœ¼ë©´ ìˆœì • ëª¨ë¸ ì‚¬ìš©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. í™˜ê²½ ì„¤ì • ë° í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!nvidia-smi\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"Install Dependencies...\")\n",
    "!pip install -q timm facenet-pytorch albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 2. ë°ì´í„° ì¤€ë¹„ (ë“œë¼ì´ë¸Œ -> ë¡œì»¬ ë³µì‚¬ ë° ì••ì¶• í•´ì œ)\n",
    "# ë“œë¼ì´ë¸Œ ê²½ë¡œ ì„¤ì • (ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)\n",
    "DRIVE_ZIP_PATH = '/content/drive/MyDrive/HAI_Deepfake/processed_test_data.zip'\n",
    "LOCAL_DATA_DIR = '/content/processed_test_data'\n",
    "\n",
    "if not os.path.exists(LOCAL_DATA_DIR):\n",
    "    print(\"ğŸ“‚ ë°ì´í„° ë³µì‚¬ ë° ì••ì¶• í•´ì œ ì¤‘... (ì•½ê°„ì˜ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤)\")\n",
    "    !cp {DRIVE_ZIP_PATH} /content/data.zip\n",
    "    !unzip -q /content/data.zip -d /content/\n",
    "    print(\"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(\"âœ… ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ëª¨ë¸ ê²½ë¡œ í™•ì¸\n",
    "MODEL_PATH = '/content/drive/MyDrive/HAI_Deepfake/checkpoints/best_model.pt'\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(f\"âœ… í•™ìŠµ ëª¨ë¸ ë°œê²¬: {MODEL_PATH}\")\n",
    "else:\n",
    "    print(\"âš ï¸ í•™ìŠµ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ìˆœì • ëª¨ë¸(Pure Pretrained) ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ì¶”ë¡  ì½”ë“œ ì‹¤í–‰ (Inference Engine)\n",
    "import torch\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "from timm.data import resolve_data_config, create_transform\n",
    "\n",
    "# ì„¤ì •\n",
    "MODEL_NAME = \"tf_efficientnetv2_m.in21k\"\n",
    "OUTPUT_CSV = \"submission.csv\"\n",
    "\n",
    "class ProcessedDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "        self.items = sorted(list(self.data_dir.glob('*')))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item_path = self.items[idx]\n",
    "        pixel_values_list = []\n",
    "        \n",
    "        if item_path.is_dir():\n",
    "            img_paths = sorted(list(item_path.glob('*.jpg')))\n",
    "            for p in img_paths:\n",
    "                img = Image.open(p).convert(\"RGB\")\n",
    "                if self.transform:\n",
    "                    pixel_values_list.append(self.transform(img))\n",
    "        else:\n",
    "            img = Image.open(item_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                pixel_values_list.append(self.transform(img))\n",
    "\n",
    "        if not pixel_values_list:\n",
    "            return torch.zeros(1, 3, 384, 384), item_path.name\n",
    "\n",
    "        return torch.stack(pixel_values_list), item_path.name\n",
    "\n",
    "def run_inference():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    print(f\"Loading model: {MODEL_NAME}\")\n",
    "    model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=2)\n",
    "    \n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        checkpoint = torch.load(MODEL_PATH, map_location='cpu')\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            state_dict = checkpoint['model_state_dict']\n",
    "            # í‚¤ ë§¤í•‘ (DDP ë“±ìœ¼ë¡œ ì¸í•´ model. ì ‘ë‘ì‚¬ê°€ ë¶™ì€ ê²½ìš° ì œê±°)\n",
    "            new_state_dict = {k.replace('model.model.', 'model.'): v for k, v in state_dict.items()} # êµ¬ì¡°ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ\n",
    "            # ë” ì•ˆì „í•œ ë§¤í•‘: timm ëª¨ë¸ì€ self.modelì´ ì•„ë‹ ìˆ˜ ìˆìŒ. ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡° í™•ì¸ í•„ìš”.\n",
    "            # ì—¬ê¸°ì„œëŠ” timm create_modelë¡œ ë§Œë“  ê°ì²´ì— ë°”ë¡œ ë¡œë“œ ì‹œë„\n",
    "            try:\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            except RuntimeError:\n",
    "                # ë§Œì•½ DeepfakeDetector ë˜í¼ë¡œ ì €ì¥ëœ ê²½ìš°\n",
    "                print(\"Load failed directly. Trying to adapt keys...\")\n",
    "                new_keys = {k.replace('model.', ''): v for k, v in checkpoint['model_state_dict'].items()}\n",
    "                model.load_state_dict(new_keys, strict=False)\n",
    "                \n",
    "        print(f\"âœ… Loaded weights from: {MODEL_PATH}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ No checkpoint found. Running in Pure Pretrained mode.\")\n",
    "    \n",
    "    model = model.to(device).eval()\n",
    "\n",
    "    # Transform\n",
    "    data_config = resolve_data_config(model.default_cfg, model=model)\n",
    "    transform = create_transform(**data_config)\n",
    "\n",
    "    # DataLoader\n",
    "    dataset = ProcessedDataset(LOCAL_DATA_DIR, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "    # ì¶”ë¡ \n",
    "    results = {}\n",
    "    print(f\"ğŸš€ Starting inference on {len(dataset)} items...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for pixel_values, filenames in tqdm(dataloader):\n",
    "            pixel_values = pixel_values.squeeze(0).to(device)\n",
    "            filename = filenames[0]\n",
    "            \n",
    "            # AMP ì ìš©\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(pixel_values)\n",
    "                probs = F.softmax(logits, dim=1)[:, 1] # Fake í™•ë¥ \n",
    "                \n",
    "            final_prob = float(probs.mean().cpu().item())\n",
    "            results[filename] = final_prob\n",
    "\n",
    "    return results\n",
    "\n",
    "results = run_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ê²°ê³¼ ì €ì¥ ë° ë‚´ë³´ë‚´ê¸°\n",
    "import pandas as pd\n",
    "\n",
    "submission = pd.DataFrame(list(results.items()), columns=['filename', 'prob'])\n",
    "\n",
    "# [ì„ íƒ] ë¼ë²¨ ë°˜ì „ì´ í•„ìš”í•œ ê²½ìš° (0.5 ì´í•˜ ì ìˆ˜ê°€ ë§ì´ ë‚˜ì˜¬ ë•Œ ì‹œë„)\n",
    "# submission['prob'] = 1.0 - submission['prob']\n",
    "\n",
    "submission.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"âœ… Submission saved: {OUTPUT_CSV}\")\n",
    "\n",
    "# ë“œë¼ì´ë¸Œë¡œ ë³µì‚¬ (ë°±ì—…)\n",
    "BACKUP_PATH = '/content/drive/MyDrive/HAI_Deepfake/submission_final.csv'\n",
    "!cp {OUTPUT_CSV} {BACKUP_PATH}\n",
    "print(f\"ğŸ’¾ Drive Backup: {BACKUP_PATH}\")\n",
    "\n",
    "# ìƒìœ„ 10ê°œ í™•ì¸\n",
    "submission.head(10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
