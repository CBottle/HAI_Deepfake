"""
ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸

Kaggle ë”¥í˜ì´í¬ ë°ì´í„°ì…‹ì˜ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
train_data/real, train_data/fake í´ë” êµ¬ì¡°ë¡œ ìë™ ì •ë¦¬í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python scripts/extract_frames.py --input datasets/faceforensics --output train_data
"""

import argparse
import cv2
import numpy as np
from pathlib import Path
from typing import List, Optional
from tqdm import tqdm
import multiprocessing as mp
from functools import partial


class VideoFrameExtractor:
    """ë¹„ë””ì˜¤ í”„ë ˆì„ ì¶”ì¶œê¸°"""

    VIDEO_EXTS = {".mp4", ".mov", ".avi", ".mkv"}

    def __init__(
        self,
        max_frames: int = 30,
        sample_method: str = "uniform",
        min_face_size: int = 64,
        quality: int = 95,
    ):
        """
        Args:
            max_frames: ë¹„ë””ì˜¤ë‹¹ ìµœëŒ€ ì¶”ì¶œ í”„ë ˆì„ ìˆ˜
            sample_method: ìƒ˜í”Œë§ ë°©ë²• ('uniform', 'random', 'first')
            min_face_size: ìµœì†Œ ì–¼êµ´ í¬ê¸° (í”½ì…€)
            quality: JPEG í’ˆì§ˆ (0-100)
        """
        self.max_frames = max_frames
        self.sample_method = sample_method
        self.min_face_size = min_face_size
        self.quality = quality

    def extract_frames_from_video(
        self, video_path: Path, output_dir: Path, label: str
    ) -> int:
        """
        ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ

        Args:
            video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            label: ë ˆì´ë¸” ('real' or 'fake')

        Returns:
            ì¶”ì¶œëœ í”„ë ˆì„ ìˆ˜
        """
        cap = cv2.VideoCapture(str(video_path))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        if total_frames <= 0:
            cap.release()
            return 0

        # ìƒ˜í”Œë§ ì¸ë±ìŠ¤ ê²°ì •
        frame_indices = self._get_frame_indices(total_frames)

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        label_dir = output_dir / label
        label_dir.mkdir(parents=True, exist_ok=True)

        # ë¹„ë””ì˜¤ ì´ë¦„ (í™•ì¥ì ì œê±°)
        video_name = video_path.stem

        extracted_count = 0

        for idx in frame_indices:
            cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))
            ret, frame = cap.read()

            if not ret:
                continue

            # RGB ë³€í™˜
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # í”„ë ˆì„ ì €ì¥
            output_path = label_dir / f"{video_name}_frame_{idx:04d}.jpg"
            cv2.imwrite(
                str(output_path),
                cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR),
                [cv2.IMWRITE_JPEG_QUALITY, self.quality],
            )
            extracted_count += 1

        cap.release()
        return extracted_count

    def _get_frame_indices(self, total_frames: int) -> List[int]:
        """
        í”„ë ˆì„ ìƒ˜í”Œë§ ì¸ë±ìŠ¤ ê³„ì‚°

        Args:
            total_frames: ì „ì²´ í”„ë ˆì„ ìˆ˜

        Returns:
            ìƒ˜í”Œë§í•  í”„ë ˆì„ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        num_frames = min(self.max_frames, total_frames)

        if self.sample_method == "uniform":
            # ê· ë“± ìƒ˜í”Œë§
            indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)

        elif self.sample_method == "random":
            # ëœë¤ ìƒ˜í”Œë§
            indices = np.random.choice(total_frames, num_frames, replace=False)
            indices = np.sort(indices)

        elif self.sample_method == "first":
            # ì²˜ìŒ Nê°œ
            indices = np.arange(num_frames)

        else:
            raise ValueError(f"Unknown sample method: {self.sample_method}")

        return indices.tolist()

    def process_dataset(
        self,
        input_dir: Path(r"D:\deepfake_Data\train"),
        output_dir: Path(r"D:\deepfake_Data\extracted_frames"),
        max_videos: Optional[int] = None,
        num_workers: int = 4,
    ):
        """
        ë°ì´í„°ì…‹ ì „ì²´ ì²˜ë¦¬

        Args:
            input_dir: ì…ë ¥ ë””ë ‰í† ë¦¬ (real/, fake/ í•˜ìœ„ í´ë” ê°€ì •)
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            max_videos: ìµœëŒ€ ì²˜ë¦¬ ë¹„ë””ì˜¤ ìˆ˜ (Noneì´ë©´ ì „ì²´)
            num_workers: ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜
        """
        print(f"ğŸ¬ ë¹„ë””ì˜¤ â†’ ì´ë¯¸ì§€ ë³€í™˜ ì‹œì‘")
        print(f"ğŸ“‚ ì…ë ¥: {input_dir}")
        print(f"ğŸ“ ì¶œë ¥: {output_dir}")
        print(f"âš™ï¸  ì„¤ì •: {self.max_frames} frames/video, {self.sample_method} sampling")
        print("-" * 70)

        # real, fake í´ë” ì°¾ê¸°
        for label in ["real", "fake"]:
            label_dir = input_dir / label

            if not label_dir.exists():
                print(f"âš ï¸  {label} í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {label_dir}")
                continue

            # ë¹„ë””ì˜¤ íŒŒì¼ ìˆ˜ì§‘
            video_files = []
            for ext in self.VIDEO_EXTS:
                video_files.extend(label_dir.glob(f"*{ext}"))

            if max_videos:
                video_files = video_files[:max_videos]

            print(f"\nğŸ“¹ {label.upper()} ë¹„ë””ì˜¤: {len(video_files)}ê°œ")

            if len(video_files) == 0:
                print(f"   âš ï¸  ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                continue

            # í”„ë ˆì„ ì¶”ì¶œ
            total_frames = 0

            for video_path in tqdm(video_files, desc=f"Processing {label}"):
                count = self.extract_frames_from_video(video_path, output_dir, label)
                total_frames += count

            print(f"   âœ… ì¶”ì¶œ ì™„ë£Œ: {total_frames} í”„ë ˆì„")

        # ê²°ê³¼ ìš”ì•½
        self.print_summary(output_dir)

    def print_summary(self, output_dir: Path):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 70)
        print("ğŸ“Š ë°ì´í„°ì…‹ ìš”ì•½")
        print("=" * 70)

        for label in ["real", "fake"]:
            label_dir = output_dir / label
            if label_dir.exists():
                images = list(label_dir.glob("*.jpg"))
                print(f"  {label.upper():5s}: {len(images):6,d} ì´ë¯¸ì§€")

        print("=" * 70)


def parse_args():
    """ëª…ë ¹í–‰ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(description="ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ")

    parser.add_argument(
        "--input",
        type=str,
        required=True,
        help="ì…ë ¥ ë””ë ‰í† ë¦¬ (real/, fake/ í•˜ìœ„ í´ë” í•„ìš”)",
    )

    parser.add_argument(
        "--output",
        type=str,
        default="train_data",
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: train_data)",
    )

    parser.add_argument(
        "--max-frames", type=int, default=30, help="ë¹„ë””ì˜¤ë‹¹ ìµœëŒ€ í”„ë ˆì„ ìˆ˜ (ê¸°ë³¸: 30)"
    )

    parser.add_argument(
        "--sample-method",
        type=str,
        choices=["uniform", "random", "first"],
        default="uniform",
        help="ìƒ˜í”Œë§ ë°©ë²• (ê¸°ë³¸: uniform)",
    )

    parser.add_argument(
        "--max-videos",
        type=int,
        default=None,
        help="ìµœëŒ€ ì²˜ë¦¬ ë¹„ë””ì˜¤ ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©, ê¸°ë³¸: ì „ì²´)",
    )

    parser.add_argument(
        "--quality", type=int, default=95, help="JPEG í’ˆì§ˆ (0-100, ê¸°ë³¸: 95)"
    )

    parser.add_argument(
        "--num-workers", type=int, default=4, help="ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸: 4)"
    )

    return parser.parse_args()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    args = parse_args()

    input_dir = Path(args.input)
    output_dir = Path(args.output)

    if not input_dir.exists():
        print(f"âŒ ì…ë ¥ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
        return

    # ì¶”ì¶œê¸° ì´ˆê¸°í™”
    extractor = VideoFrameExtractor(
        max_frames=args.max_frames,
        sample_method=args.sample_method,
        quality=args.quality,
    )

    # ì²˜ë¦¬ ì‹œì‘
    extractor.process_dataset(
        input_dir=input_dir,
        output_dir=output_dir,
        max_videos=args.max_videos,
        num_workers=args.num_workers,
    )

    print("\nâœ… ëª¨ë“  í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ!")
    print(f"ğŸ“ ì¶œë ¥ ìœ„ì¹˜: {output_dir.absolute()}")


if __name__ == "__main__":
    main()
